# Server host/interface. Use "127.0.0.1" or "localhost" to restrict access to local machine only.
host: ""

# Any string value can be sourced from an environment variable by using:
#   os.environ/ENV_VAR_NAME
# Example:
#   remote-management:
#     secret-key: os.environ/MANAGEMENT_PASSWORD

# Strict YAML parsing (reject unknown fields). Useful to catch typos.
# strict-config: true

# Server port
port: 8317

# TLS settings for HTTPS. When enabled, the server listens with the provided certificate and key.
tls:
  enable: false
  cert: ""
  key: ""

# Management API settings
remote-management:
  # Whether to allow remote (non-localhost) management access.
  # When false, only localhost can access management endpoints (a key is still required).
  allow-remote: false

  # Management key. If a plaintext value is provided here, it will be hashed on startup.
  # All management requests (even from localhost) require this key.
  # Leave empty to disable the Management API entirely (404 for all /v0/management routes).
  secret-key: ""

  # Disable the bundled management control panel asset download and HTTP route when true.
  disable-control-panel: false

  # Allow downloading auth JSON files via management endpoints from non-localhost clients.
  # Disabled by default to reduce the risk of credential exfiltration.
  allow-auth-file-download: false

  # GitHub repository for the management control panel. Accepts a repository URL or releases API URL.
  panel-github-repository: "https://github.com/router-for-me/Cli-Proxy-API-Management-Center"

# Authentication directory (supports ~ for home directory)
auth-dir: "~/.cli-proxy-api"

# Auth file storage settings (credentials saved under auth-dir as *.json)
auth-storage:
  # Encrypt auth JSON at rest. If omitted, encryption is auto-enabled when an encryption key is present.
  # encrypt: true
  # Encryption key secret. Prefer setting via env (CLIPROXY_AUTH_ENCRYPTION_KEY) and referencing it:
  # encryption-key: os.environ/CLIPROXY_AUTH_ENCRYPTION_KEY
  # Allow reading legacy plaintext auth JSON when encryption is enabled (best-effort migrates to encrypted).
  # allow-plaintext-fallback: true

# API keys for authentication
api-keys:
  - "your-api-key-1"
  - "your-api-key-2"

# Enable debug logging
debug: false

# When true, write application logs to rotating files instead of stdout
logging-to-file: false

# When false, disable in-memory usage statistics aggregation
usage-statistics-enabled: false

# Proxy URL. Supports socks5/http/https protocols. Example: socks5://user:pass@192.168.1.1:1080/
proxy-url: ""

# Security guardrails. When disabled (default), requests containing api_base/base_url fields are rejected.
# security:
#   allow-client-side-credentials: false

# Request/response size limits (max_request_size_mb/max_response_size_mb).
# limits:
#   max-request-size-mb: 10
#   max-response-size-mb: 50

# Number of times to retry a request. Retries will occur if the HTTP response code is 403, 408, 500, 502, 503, or 504.
request-retry: 3

# Maximum wait time in seconds for a cooled-down credential before triggering a retry.
max-retry-interval: 30

# When true, disable quota backoff cooldown scheduling for 429 errors (not recommended).
disable-cooling: false

# Quota exceeded behavior
quota-exceeded:
  switch-project: true # Whether to automatically switch to another project when a quota is exceeded
  switch-preview-model: true # Whether to automatically switch to a preview model when a quota is exceeded

# When true, enable authentication for the WebSocket API (/v1/ws).
ws-auth: false

# Response caching configuration
# cache:
#   enable: true           # Enable response caching
#   max-size: 1000         # Maximum number of cached responses
#   ttl: 300               # Cache TTL in seconds (default: 5 minutes)

# Rate limiting configuration
# rate-limits:
#   enable: true                  # Enable rate limiting
#   max-parallel-requests: 100    # Maximum concurrent requests globally
#   max-per-key: 10               # Maximum concurrent requests per API key
#   max-rpm: 60                   # Maximum requests per minute per key
#   max-tpm: 120000               # Maximum tokens per minute per API key

# Prometheus metrics configuration
# metrics:
#   enable: true           # Enable metrics endpoint
#   endpoint: "/metrics"   # HTTP path for metrics
#   require-auth: false    # When true, /metrics requires normal API auth

# Credential cooldown configuration
# cooldown:
#   enable: true           # Enable automatic cooldown on errors
#   duration: 60           # Cooldown duration in seconds
#   trigger-on:            # HTTP status codes that trigger cooldown
#     - 429
#     - 500
#     - 502
#     - 503
#     - 504

# Routing / selection strategy when multiple credentials match.
# routing:
#   strategy: "fill-first"    # fill-first (default), round-robin, random, least-busy, lowest-latency
#   health-aware: true        # Filter unhealthy credentials (COOLDOWN, ERROR)
#   prefer-healthy: true      # Prefer HEALTHY over DEGRADED when health-aware
#   fill-first-max-inflight-per-auth: 4  # Default: 4 (nil). 0 = unlimited
#   fill-first-spillover: "next-auth"   # next-auth (default), least-busy

# Health tracking (feeds health-aware routing + readiness checks).
# health-tracking:
#   enable: true
#   window-seconds: 60
#   failure-threshold: 0.5
#   degraded-threshold: 0.1
#   min-requests: 5
#   cleanup-interval: 300

# Fallback chains (model/provider failover).
# Fallbacks are attempted on transient failures (network, 408, 429, 5xx).
# fallback-chains:
#   enable: true
#   chains:
#     - primary-model: "gpt-4o"
#       primary-provider: "openai"   # optional
#       fallbacks:
#         - model: "claude-3-5-sonnet-20241022"
#           provider: "claude"
#         - model: "gemini-2.0-flash-exp"
#           provider: "gemini"

# Retry policy (exponential backoff).
# Applies to transient failures (network, 408, 5xx). 429 relies on cooldown/Retry-After instead.
# retry-policy:
#   enable: true
#   max-retries: 3
#   initial-delay-ms: 1000
#   max-delay-ms: 30000
#   multiplier: 2.0
#   jitter: 0.1

# Streaming behavior (SSE keep-alives + safe stream bootstrap retries).
# streaming:
#   keepalive-seconds: 15     # Default: 15 (nil). <= 0 disables keep-alives
#   bootstrap-retries: 2      # Default: 2 (nil). 0 disables bootstrap retries

# Virtual keys (managed client keys).
# virtual-keys:
#   enable: true
#   store-file: ""          # default: <auth-dir>/virtual_keys.json
#   flush-interval: 5       # seconds

# Pricing table (for spend/budget enforcement on virtual keys).
# pricing:
#   enable: true
#   default:
#     input-per-1k: 0.0
#     output-per-1k: 0.0
#   models:
#     - match: "gpt-4o*"
#       input-per-1k: 5.0
#       output-per-1k: 15.0

# Pass-through endpoints (forward unimplemented routes upstream).
# pass-through:
#   enable: true
#   endpoints:
#     - path: "/v1/rerank"
#       method: "POST"
#       base-url: "https://api.openai.com" # note: do not include /v1 to avoid double /v1/v1
#       timeout: 60
#       headers:
#         Authorization: "Bearer os.environ/OPENAI_API_KEY"

# Health endpoints + optional background probes (lightweight TCP dials).
# health:
#   background-checks:
#     enable: true
#     interval: 300         # seconds

# Gemini API keys
# gemini-api-key:
#   - api-key: "AIzaSy...01"
#     base-url: "https://generativelanguage.googleapis.com"
#     headers:
#       X-Custom-Header: "custom-value"
#     proxy-url: "socks5://proxy.example.com:1080"
#     excluded-models:
#       - "gemini-2.5-pro"     # exclude specific models from this provider (exact match)
#       - "gemini-2.5-*"       # wildcard matching prefix (e.g. gemini-2.5-flash, gemini-2.5-pro)
#       - "*-preview"          # wildcard matching suffix (e.g. gemini-3-pro-preview)
#       - "*flash*"            # wildcard matching substring (e.g. gemini-2.5-flash-lite)
#   - api-key: "AIzaSy...02"

# Codex API keys
# codex-api-key:
#   - api-key: "sk-atSM..."
#     base-url: "https://www.example.com" # use the custom codex API endpoint
#     headers:
#       X-Custom-Header: "custom-value"
#     proxy-url: "socks5://proxy.example.com:1080" # optional: per-key proxy override
#     excluded-models:
#       - "gpt-5.1"         # exclude specific models (exact match)
#       - "gpt-5-*"         # wildcard matching prefix (e.g. gpt-5-medium, gpt-5-codex)
#       - "*-mini"          # wildcard matching suffix (e.g. gpt-5-codex-mini)
#       - "*codex*"         # wildcard matching substring (e.g. gpt-5-codex-low)

# Claude API keys
# claude-api-key:
#   - api-key: "sk-atSM..." # use the official claude API key, no need to set the base url
#   - api-key: "sk-atSM..."
#     base-url: "https://www.example.com" # use the custom claude API endpoint
#     headers:
#       X-Custom-Header: "custom-value"
#     proxy-url: "socks5://proxy.example.com:1080" # optional: per-key proxy override
#     models:
#       - name: "claude-3-5-sonnet-20241022" # upstream model name
#         alias: "claude-sonnet-latest" # client alias mapped to the upstream model
#     excluded-models:
#       - "claude-opus-4-5-20251101" # exclude specific models (exact match)
#       - "claude-3-*"               # wildcard matching prefix (e.g. claude-3-7-sonnet-20250219)
#       - "*-think"                  # wildcard matching suffix (e.g. claude-opus-4-5-thinking)
#       - "*haiku*"                  # wildcard matching substring (e.g. claude-3-5-haiku-20241022)

# OpenAI compatibility providers
# openai-compatibility:
#   - name: "openrouter" # The name of the provider; it will be used in the user agent and other places.
#     base-url: "https://openrouter.ai/api/v1" # The base URL of the provider.
#     headers:
#       X-Custom-Header: "custom-value"
#     api-key-entries:
#       - api-key: "sk-or-v1-...b780"
#         proxy-url: "socks5://proxy.example.com:1080" # optional: per-key proxy override
#       - api-key: "sk-or-v1-...b781" # without proxy-url
#     models: # The models supported by the provider.
#       - name: "moonshotai/kimi-k2:free" # The actual model name.
#         alias: "kimi-k2" # The alias used in the API.

# Vertex API keys (Vertex-compatible endpoints, use API key + base URL)
# vertex-api-key:
#   - api-key: "vk-123..."                        # x-goog-api-key header
#     base-url: "https://example.com/api"         # e.g. https://zenmux.ai/api
#     proxy-url: "socks5://proxy.example.com:1080" # optional per-key proxy override
#     headers:
#       X-Custom-Header: "custom-value"
#     models:                                     # optional: map aliases to upstream model names
#       - name: "gemini-2.0-flash"                # upstream model name
#         alias: "vertex-flash"                   # client-visible alias
#       - name: "gemini-1.5-pro"
#         alias: "vertex-pro"

# Amp Integration
# ampcode:
#   # Configure upstream URL for Amp CLI OAuth and management features
#   upstream-url: "https://ampcode.com"
#   # Optional: Override API key for Amp upstream (otherwise uses env or file)
#   upstream-api-key: ""
#   # Restrict Amp management routes (/api/auth, /api/user, etc.) to localhost only (recommended)
#   restrict-management-to-localhost: true
#   # Amp Model Mappings
#   # Route unavailable Amp models to alternative models available in your local proxy.
#   # Useful when Amp CLI requests models you don't have access to (e.g., Claude Opus 4.5)
#   # but you have a similar model available (e.g., Claude Sonnet 4).
#   model-mappings:
#     - from: "claude-opus-4.5"       # Model requested by Amp CLI
#       to: "claude-sonnet-4"         # Route to this available model instead
#     - from: "gpt-5"
#       to: "gemini-2.5-pro"
#     - from: "claude-3-opus-20240229"
#       to: "claude-3-5-sonnet-20241022"

# OAuth provider excluded models
# oauth-excluded-models:
#   gemini-cli:
#     - "gemini-2.5-pro"     # exclude specific models (exact match)
#     - "gemini-2.5-*"       # wildcard matching prefix (e.g. gemini-2.5-flash, gemini-2.5-pro)
#     - "*-preview"          # wildcard matching suffix (e.g. gemini-3-pro-preview)
#     - "*flash*"            # wildcard matching substring (e.g. gemini-2.5-flash-lite)
#   vertex:
#     - "gemini-3-pro-preview"
#   aistudio:
#     - "gemini-3-pro-preview"
#   antigravity:
#     - "gemini-3-pro-preview"
#   claude:
#     - "claude-3-5-haiku-20241022"
#   codex:
#     - "gpt-5-codex-mini"
#   qwen:
#     - "vision-model"
#   iflow:
#     - "tstars2.0"

# Optional payload configuration
# payload:
#   default: # Default rules only set parameters when they are missing in the payload.
#     - models:
#         - name: "gemini-2.5-pro" # Supports wildcards (e.g., "gemini-*")
#           protocol: "gemini" # restricts the rule to a specific protocol, options: openai, gemini, claude, codex
#       params: # JSON path (gjson/sjson syntax) -> value
#         "generationConfig.thinkingConfig.thinkingBudget": 32768
#   override: # Override rules always set parameters, overwriting any existing values.
#     - models:
#         - name: "gpt-*" # Supports wildcards (e.g., "gpt-*")
#           protocol: "codex" # restricts the rule to a specific protocol, options: openai, gemini, claude, codex
#       params: # JSON path (gjson/sjson syntax) -> value
#         "reasoning.effort": "high"
