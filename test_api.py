#!/usr/bin/env python3
"""
CLIProxyAPI å…¨é¢æµ‹è¯•è„šæœ¬
æµ‹è¯•æ¨¡å‹åˆ—è¡¨ã€æµå¼è¾“å‡ºã€thinkingæ¨¡å¼åŠå¤æ‚ä»»åŠ¡
"""

import requests
import json
import time
import sys
import io
from typing import Optional, List, Dict, Any

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# é…ç½®
BASE_URL = "http://localhost:8317"
API_KEY = "your-api-key-1"
HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}

# å¤æ‚ä»»åŠ¡æç¤ºè¯ - ç”¨äºæµ‹è¯• thinking æ¨¡å¼
COMPLEX_TASK_PROMPT = """è¯·å¸®æˆ‘åˆ†æä»¥ä¸‹å¤æ‚çš„ç¼–ç¨‹é—®é¢˜ï¼Œå¹¶ç»™å‡ºè¯¦ç»†çš„è§£å†³æ–¹æ¡ˆï¼š

é—®é¢˜ï¼šè®¾è®¡ä¸€ä¸ªé«˜å¹¶å‘çš„åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿï¼Œéœ€è¦æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š
1. æ”¯æŒç™¾ä¸‡çº§ä»»åŠ¡é˜Ÿåˆ—
2. ä»»åŠ¡å¯ä»¥è®¾ç½®ä¼˜å…ˆçº§ã€å»¶è¿Ÿæ‰§è¡Œã€å®šæ—¶æ‰§è¡Œ
3. æ”¯æŒä»»åŠ¡ä¾èµ–å…³ç³»ï¼ˆDAGè°ƒåº¦ï¼‰
4. å¤±è´¥é‡è¯•æœºåˆ¶ï¼Œæ”¯æŒæŒ‡æ•°é€€é¿
5. ä»»åŠ¡ç»“æœæŒä¹…åŒ–å’ŒæŸ¥è¯¢
6. æ°´å¹³æ‰©å±•èƒ½åŠ›
7. ç›‘æ§å’Œå‘Šè­¦

è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¯¦ç»†åˆ†æï¼š
1. æ•´ä½“æ¶æ„è®¾è®¡
2. æ ¸å¿ƒæ•°æ®ç»“æ„
3. è°ƒåº¦ç®—æ³•é€‰æ‹©
4. å®¹é”™æœºåˆ¶è®¾è®¡
5. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
6. æŠ€æœ¯é€‰å‹å»ºè®®

è¯·é€æ­¥æ€è€ƒæ¯ä¸ªæ–¹é¢ï¼Œç»™å‡ºä½ çš„æ¨ç†è¿‡ç¨‹ã€‚"""

# ç®€å•æµ‹è¯•æç¤ºè¯
SIMPLE_PROMPT = "Hello! Please respond with 'OK' if you receive this message."

def print_separator(title: str):
    print(f"\n{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}\n")

def print_result(name: str, success: bool, detail: str = ""):
    status = "âœ… PASS" if success else "âŒ FAIL"
    print(f"{status} | {name}")
    if detail:
        print(f"       â””â”€ {detail[:200]}{'...' if len(detail) > 200 else ''}")

def get_models() -> List[str]:
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    print_separator("è·å–æ¨¡å‹åˆ—è¡¨")
    try:
        resp = requests.get(f"{BASE_URL}/v1/models", headers=HEADERS, timeout=30)
        if resp.status_code == 200:
            data = resp.json()
            models = [m.get("id", m.get("name", "unknown")) for m in data.get("data", [])]
            print(f"æ‰¾åˆ° {len(models)} ä¸ªæ¨¡å‹:")
            for m in models:
                print(f"  - {m}")
            return models
        else:
            print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: HTTP {resp.status_code}")
            print(f"   å“åº”: {resp.text[:500]}")
            return []
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¼‚å¸¸: {e}")
        return []

def test_model_basic(model: str) -> tuple:
    """åŸºç¡€å¯ç”¨æ€§æµ‹è¯•ï¼Œè¿”å› (success, error_detail)"""
    try:
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": SIMPLE_PROMPT}],
            "max_tokens": 50,
            "stream": False
        }
        resp = requests.post(
            f"{BASE_URL}/v1/chat/completions",
            headers=HEADERS,
            json=payload,
            timeout=60
        )
        if resp.status_code == 200:
            data = resp.json()
            content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
            return (bool(content), f"content_len={len(content)}")
        else:
            return (False, f"HTTP {resp.status_code}: {resp.text[:300]}")
    except Exception as e:
        return (False, str(e))

def test_streaming(model: str) -> Dict[str, Any]:
    """æµ‹è¯•æµå¼è¾“å‡º"""
    result = {"success": False, "chunks": 0, "content": "", "error": None}
    try:
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": "Count from 1 to 5, one number per line."}],
            "max_tokens": 100,
            "stream": True
        }
        resp = requests.post(
            f"{BASE_URL}/v1/chat/completions",
            headers=HEADERS,
            json=payload,
            timeout=60,
            stream=True
        )
        
        if resp.status_code != 200:
            result["error"] = f"HTTP {resp.status_code}: {resp.text[:200]}"
            return result
        
        content_parts = []
        for line in resp.iter_lines():
            if line:
                line_str = line.decode('utf-8')
                if line_str.startswith("data: "):
                    data_str = line_str[6:]
                    if data_str.strip() == "[DONE]":
                        break
                    try:
                        data = json.loads(data_str)
                        result["chunks"] += 1
                        choices = data.get("choices", [])
                        if choices:
                            delta = choices[0].get("delta", {})
                            if "content" in delta and delta["content"]:
                                content_parts.append(delta["content"])
                    except json.JSONDecodeError:
                        pass
                    except Exception as e:
                        result["error"] = f"Parse error: {e}, data: {data_str[:200]}"
        
        result["content"] = "".join(content_parts)
        result["success"] = result["chunks"] > 0 and len(result["content"]) > 0
        
    except Exception as e:
        result["error"] = str(e)
    
    return result

def test_thinking_mode(model: str, complex_task: bool = False) -> Dict[str, Any]:
    """æµ‹è¯• thinking æ¨¡å¼"""
    result = {
        "success": False, 
        "has_reasoning": False,
        "reasoning_content": "",
        "content": "", 
        "error": None,
        "chunks": 0
    }
    
    prompt = COMPLEX_TASK_PROMPT if complex_task else "What is 15 * 23? Please think step by step."
    
    try:
        # å°è¯•ä¸åŒçš„ thinking æ¨¡å¼å‚æ•°æ ¼å¼
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 8000 if complex_task else 2000,
            "stream": True
        }
        
        # æ ¹æ®æ¨¡å‹ç±»å‹æ·»åŠ  thinking å‚æ•°
        if "claude" in model.lower():
            payload["thinking"] = {"type": "enabled", "budget_tokens": 5000 if complex_task else 2000}
        elif "gemini" in model.lower():
            payload["thinking"] = {"thinking_budget": 5000 if complex_task else 2000}
        elif "gpt" in model.lower() or "codex" in model.lower() or "o1" in model.lower() or "o3" in model.lower():
            payload["reasoning_effort"] = "high" if complex_task else "medium"
        else:
            # é€šç”¨æ ¼å¼
            payload["thinking"] = {"type": "enabled", "budget_tokens": 5000 if complex_task else 2000}
        
        resp = requests.post(
            f"{BASE_URL}/v1/chat/completions",
            headers=HEADERS,
            json=payload,
            timeout=300 if complex_task else 120,
            stream=True
        )
        
        if resp.status_code != 200:
            result["error"] = f"HTTP {resp.status_code}: {resp.text[:500]}"
            return result
        
        content_parts = []
        reasoning_parts = []
        
        for line in resp.iter_lines():
            if line:
                line_str = line.decode('utf-8')
                if line_str.startswith("data: "):
                    data_str = line_str[6:]
                    if data_str.strip() == "[DONE]":
                        break
                    try:
                        data = json.loads(data_str)
                        result["chunks"] += 1
                        
                        choices = data.get("choices", [])
                        if not choices:
                            continue
                        choice = choices[0]
                        delta = choice.get("delta", {})
                        
                        # æ£€æŸ¥ reasoning_content (Claude/OpenAIæ ¼å¼)
                        if "reasoning_content" in delta and delta["reasoning_content"]:
                            reasoning_parts.append(delta["reasoning_content"])
                            result["has_reasoning"] = True
                        
                        # æ£€æŸ¥ thinking (Geminiæ ¼å¼)
                        if "thinking" in delta and delta["thinking"]:
                            reasoning_parts.append(delta["thinking"])
                            result["has_reasoning"] = True
                        
                        # å¸¸è§„å†…å®¹
                        if "content" in delta and delta["content"]:
                            content_parts.append(delta["content"])
                            
                    except json.JSONDecodeError as e:
                        pass
                    except Exception as e:
                        result["error"] = f"Parse error: {e}"
        
        result["reasoning_content"] = "".join(reasoning_parts)
        result["content"] = "".join(content_parts)
        result["success"] = result["chunks"] > 0 and (len(result["content"]) > 0 or len(result["reasoning_content"]) > 0)
        
    except requests.exceptions.Timeout:
        result["error"] = "Request timeout"
    except Exception as e:
        result["error"] = str(e)
    
    return result

def run_full_test():
    """è¿è¡Œå®Œæ•´æµ‹è¯•"""
    print("\n" + "="*60)
    print("   CLIProxyAPI å…¨é¢æµ‹è¯•")
    print("="*60)
    print(f"ç›®æ ‡åœ°å€: {BASE_URL}")
    print(f"API Key: {API_KEY[:10]}...")
    
    # 1. è·å–æ¨¡å‹åˆ—è¡¨
    models = get_models()
    if not models:
        print("\nâŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œæµ‹è¯•ç»ˆæ­¢")
        return
    
    # 2. åŸºç¡€å¯ç”¨æ€§æµ‹è¯•
    print_separator("åŸºç¡€å¯ç”¨æ€§æµ‹è¯•")
    available_models = []
    for model in models:
        success, detail = test_model_basic(model)
        print_result(f"æ¨¡å‹: {model}", success, detail)
        if success:
            available_models.append(model)
    
    print(f"\nå¯ç”¨æ¨¡å‹: {len(available_models)}/{len(models)}")
    
    if not available_models:
        print("\nâŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œæµ‹è¯•ç»ˆæ­¢")
        return
    
    # 3. æµå¼è¾“å‡ºæµ‹è¯•
    print_separator("æµå¼è¾“å‡ºæµ‹è¯•")
    streaming_results = {}
    for model in available_models:
        result = test_streaming(model)
        streaming_results[model] = result
        detail = f"chunks={result['chunks']}, content_len={len(result['content'])}"
        if result["error"]:
            detail = f"error: {result['error']}"
        print_result(f"æ¨¡å‹: {model}", result["success"], detail)
    
    # 4. Thinking æ¨¡å¼æµ‹è¯• (ç®€å•ä»»åŠ¡)
    print_separator("Thinking æ¨¡å¼æµ‹è¯• (ç®€å•ä»»åŠ¡)")
    thinking_results = {}
    for model in available_models:
        result = test_thinking_mode(model, complex_task=False)
        thinking_results[model] = result
        detail = f"reasoning={result['has_reasoning']}, chunks={result['chunks']}"
        if result["error"]:
            detail = f"error: {result['error']}"
        print_result(f"æ¨¡å‹: {model}", result["success"], detail)
    
    # 5. Thinking æ¨¡å¼æµ‹è¯• (å¤æ‚ä»»åŠ¡) - åªæµ‹è¯•æ”¯æŒ thinking çš„æ¨¡å‹
    print_separator("Thinking æ¨¡å¼æµ‹è¯• (å¤æ‚ä»»åŠ¡)")
    complex_thinking_results = {}
    
    # é€‰æ‹©å‰3ä¸ªå¯ç”¨æ¨¡å‹è¿›è¡Œå¤æ‚ä»»åŠ¡æµ‹è¯•
    test_models = available_models[:3]
    print(f"æµ‹è¯•æ¨¡å‹ (å–å‰3ä¸ª): {test_models}\n")
    
    for model in test_models:
        print(f"â³ æ­£åœ¨æµ‹è¯• {model} (å¤æ‚ä»»åŠ¡ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´)...")
        result = test_thinking_mode(model, complex_task=True)
        complex_thinking_results[model] = result
        
        if result["success"]:
            detail = f"reasoning={result['has_reasoning']}, reasoning_len={len(result['reasoning_content'])}, content_len={len(result['content'])}"
        else:
            detail = f"error: {result['error']}" if result["error"] else "Unknown error"
        
        print_result(f"æ¨¡å‹: {model}", result["success"], detail)
        
        # å¦‚æœæœ‰ reasoning å†…å®¹ï¼Œæ‰“å°å‰500å­—ç¬¦
        if result["has_reasoning"] and result["reasoning_content"]:
            print(f"\n       ğŸ“ Reasoning å†…å®¹é¢„è§ˆ (å‰500å­—ç¬¦):")
            print(f"       {result['reasoning_content'][:500]}...")
    
    # 6. æ€»ç»“æŠ¥å‘Š
    print_separator("æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    
    print(f"ğŸ“Š æ¨¡å‹æ€»æ•°: {len(models)}")
    print(f"âœ… å¯ç”¨æ¨¡å‹: {len(available_models)}")
    print(f"âŒ ä¸å¯ç”¨æ¨¡å‹: {len(models) - len(available_models)}")
    
    print(f"\nğŸ“Š æµå¼è¾“å‡ºæµ‹è¯•:")
    streaming_pass = sum(1 for r in streaming_results.values() if r["success"])
    print(f"   é€šè¿‡: {streaming_pass}/{len(streaming_results)}")
    
    print(f"\nğŸ“Š Thinking æ¨¡å¼æµ‹è¯• (ç®€å•):")
    thinking_pass = sum(1 for r in thinking_results.values() if r["success"])
    thinking_with_reasoning = sum(1 for r in thinking_results.values() if r["has_reasoning"])
    print(f"   é€šè¿‡: {thinking_pass}/{len(thinking_results)}")
    print(f"   åŒ…å«æ¨ç†å†…å®¹: {thinking_with_reasoning}/{len(thinking_results)}")
    
    print(f"\nğŸ“Š Thinking æ¨¡å¼æµ‹è¯• (å¤æ‚):")
    complex_pass = sum(1 for r in complex_thinking_results.values() if r["success"])
    complex_with_reasoning = sum(1 for r in complex_thinking_results.values() if r["has_reasoning"])
    print(f"   é€šè¿‡: {complex_pass}/{len(complex_thinking_results)}")
    print(f"   åŒ…å«æ¨ç†å†…å®¹: {complex_with_reasoning}/{len(complex_thinking_results)}")
    
    # åˆ—å‡ºæ‰€æœ‰é”™è¯¯
    print(f"\nğŸ“‹ é”™è¯¯è¯¦æƒ…:")
    has_errors = False
    
    for model, result in streaming_results.items():
        if result["error"]:
            has_errors = True
            print(f"   [æµå¼] {model}: {result['error'][:100]}")
    
    for model, result in thinking_results.items():
        if result["error"]:
            has_errors = True
            print(f"   [Thinkingç®€å•] {model}: {result['error'][:100]}")
    
    for model, result in complex_thinking_results.items():
        if result["error"]:
            has_errors = True
            print(f"   [Thinkingå¤æ‚] {model}: {result['error'][:100]}")
    
    if not has_errors:
        print("   æ— é”™è¯¯")
    
    print("\n" + "="*60)
    print("   æµ‹è¯•å®Œæˆ")
    print("="*60 + "\n")

def test_single_model_basic(model: str):
    """å•ç‹¬æµ‹è¯•ä¸€ä¸ªæ¨¡å‹çš„åŸºç¡€åŠŸèƒ½"""
    print_separator(f"åŸºç¡€æµ‹è¯•: {model}")
    success, detail = test_model_basic(model)
    print_result(f"æ¨¡å‹: {model}", success, detail)
    return success

def test_single_model_streaming(model: str):
    """å•ç‹¬æµ‹è¯•ä¸€ä¸ªæ¨¡å‹çš„æµå¼è¾“å‡º"""
    print_separator(f"æµå¼æµ‹è¯•: {model}")
    result = test_streaming(model)
    detail = f"chunks={result['chunks']}, content_len={len(result['content'])}"
    if result["error"]:
        detail = f"error: {result['error']}"
    print_result(f"æ¨¡å‹: {model}", result["success"], detail)
    if result["content"]:
        print(f"\nå†…å®¹: {result['content'][:300]}")
    return result

def test_single_model_thinking(model: str, complex_task: bool = False):
    """å•ç‹¬æµ‹è¯•ä¸€ä¸ªæ¨¡å‹çš„thinkingæ¨¡å¼"""
    task_type = "å¤æ‚" if complex_task else "ç®€å•"
    print_separator(f"Thinkingæµ‹è¯•({task_type}): {model}")
    result = test_thinking_mode(model, complex_task=complex_task)
    detail = f"reasoning={result['has_reasoning']}, chunks={result['chunks']}"
    if result["error"]:
        detail = f"error: {result['error']}"
    print_result(f"æ¨¡å‹: {model}", result["success"], detail)
    if result["reasoning_content"]:
        print(f"\nReasoningé¢„è§ˆ: {result['reasoning_content'][:500]}")
    if result["content"]:
        print(f"\nå†…å®¹é¢„è§ˆ: {result['content'][:500]}")
    return result

def print_usage():
    print("""
ç”¨æ³•: python test_api.py <command> [options]

å‘½ä»¤:
  models              - è·å–æ¨¡å‹åˆ—è¡¨
  basic <model>       - æµ‹è¯•å•ä¸ªæ¨¡å‹åŸºç¡€åŠŸèƒ½
  stream <model>      - æµ‹è¯•å•ä¸ªæ¨¡å‹æµå¼è¾“å‡º
  thinking <model>    - æµ‹è¯•å•ä¸ªæ¨¡å‹thinkingæ¨¡å¼(ç®€å•ä»»åŠ¡)
  thinking-complex <model> - æµ‹è¯•å•ä¸ªæ¨¡å‹thinkingæ¨¡å¼(å¤æ‚ä»»åŠ¡)
  all                 - è¿è¡Œå®Œæ•´æµ‹è¯•(åŸæœ‰åŠŸèƒ½)

ç¤ºä¾‹:
  python test_api.py models
  python test_api.py basic claude-sonnet
  python test_api.py stream claude-sonnet
  python test_api.py thinking claude-sonnet
""")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print_usage()
        sys.exit(0)
    
    cmd = sys.argv[1].lower()
    
    if cmd == "models":
        get_models()
    elif cmd == "basic" and len(sys.argv) >= 3:
        test_single_model_basic(sys.argv[2])
    elif cmd == "stream" and len(sys.argv) >= 3:
        test_single_model_streaming(sys.argv[2])
    elif cmd == "thinking" and len(sys.argv) >= 3:
        test_single_model_thinking(sys.argv[2], complex_task=False)
    elif cmd == "thinking-complex" and len(sys.argv) >= 3:
        test_single_model_thinking(sys.argv[2], complex_task=True)
    elif cmd == "all":
        run_full_test()
    else:
        print_usage()
